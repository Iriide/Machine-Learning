# -*- coding: utf-8 -*-
"""lab11.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qKXxa4xEJVBGIsLE_TYG2jd-xdEBwdbl
"""

from sklearn.datasets import fetch_california_housing
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from scipy.stats import reciprocal
from sklearn.model_selection import RandomizedSearchCV
import keras
import keras_tuner as kt
import numpy as np
from keras.optimizers import SGD, Adam
from scikeras.wrappers import KerasRegressor
import pickle
import os

"""2.1  Pobieranie danych"""

housing = fetch_california_housing()

X_train_full, X_test, y_train_full, y_test=train_test_split(housing.data, housing.target, random_state=42)
X_train, X_valid, y_train, y_valid=train_test_split(X_train_full,y_train_full, random_state=42)

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_valid = scaler.transform(X_valid)
X_test = scaler.transform(X_test)

"""2.2  Przeszukiwanie przestrzeni hiperparametrów przy pomocy scikit-learn"""

param_distribs={"model__n_hidden": [0, 1, 2, 3],"model__n_neurons": np.arange(1, 100).tolist(),"model__learning_rate": reciprocal(3e-4,3e-2).rvs(1000).tolist(),"model__optimizer": ["adam", "sgd", "nesterov", "momentum"], "model__momentum": [0.0, 0.2, 0.4, 0.6, 0.8, 0.9]}

def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, optimizer="adam", input_shape = X_train.shape, momentum = 0.0):
    model = keras.models.Sequential()

    model.add(keras.layers.InputLayer(input_shape=[8]))
    for layer in range(n_hidden):
        model.add(keras.layers.Dense(n_neurons, activation="relu"))
    model.add(keras.layers.Dense(1))

    if optimizer == "sgd":
        opt = SGD(learning_rate=learning_rate)
    elif optimizer == "nesterov":
        opt = SGD(learning_rate=learning_rate, momentum=0.9, nesterov=True)
    elif optimizer == "adam":
        opt = Adam(learning_rate=learning_rate)
    elif optimizer == "momentum":
        opt = SGD(learning_rate=learning_rate, momentum=momentum)

    model.compile(loss="mse", optimizer=opt)
    return model

es=keras.callbacks.EarlyStopping(patience=10, min_delta=1.0, verbose=1)
keras_reg = KerasRegressor(build_model, callbacks=[es])

rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=10, cv=3, verbose=2)
rnd_search_cv.fit(X_train, y_train, epochs=100, validation_data=(X_valid, y_valid))

best_params = rnd_search_cv.best_params_
print(best_params)
with open('rnd_search_params.pkl', 'wb') as f:
    pickle.dump(best_params, f)

with open('rnd_search_scikeras.pkl', 'wb') as f:
    pickle.dump(rnd_search_cv, f)

"""2.3  Przeszukiwanie przestrzeni hiperparametrów przy pomocy Keras Tuner"""

def build_model(hp):
    n_hidden = hp.Int('n_hidden', min_value=0, max_value=3, default=2)
    n_neurons = hp.Int('n_neurons', min_value=1, max_value=100, default=30)
    learning_rate = hp.Choice('learning_rate', values=[1e-3, 3e-3, 1e-2, 3e-2])
    optimizer = hp.Choice('optimizer', values=['adam', 'sgd', 'nesterov'])

    model = keras.models.Sequential()
    model.add(keras.layers.InputLayer(input_shape=X_train[0].shape))

    for layer in range(n_hidden):
        model.add(keras.layers.Dense(n_neurons, activation="relu"))
    model.add(keras.layers.Dense(1))

    if optimizer == "adam":
        optimizer = keras.optimizers.Adam(learning_rate=learning_rate)
    elif optimizer == "sgd":
        optimizer = keras.optimizers.SGD(learning_rate=learning_rate)
    elif optimizer == "nesterov":
        optimizer = keras.optimizers.SGD(learning_rate=learning_rate, nesterov=True)

    model.compile(loss="mse", optimizer=optimizer, metrics=["mse"])
    return model


rst = kt.RandomSearch(
build_model, objective="val_mse", max_trials=10, overwrite=True,
directory="my_california_housing", project_name="my_rnd_search", seed=42)

root_logdir = os.path.join(rst.project_dir, 'tensorboard')
tb = keras.callbacks.TensorBoard(root_logdir)

rst.search(X_train, y_train, epochs=100, validation_data=(X_valid, y_valid), callbacks=[tb, es])
rst.results_summary()



with open('kt_search_params.pkl', 'wb') as f:
    pickle.dump(rst.get_best_hyperparameters()[0].values, f)

rst.get_best_models(num_models=1)[0].save('kt_best_model.h5')